{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "tf.compat.v1.disable_eager_execution() #to use K.gradients!\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, is_bgr=True):\n",
    "    \"\"\"Function to display image\n",
    "        Args: \n",
    "            img: numpy.ndarray\n",
    "            is_bgr: bool. True: accepts BGR image.\n",
    "\n",
    "        Returns: \n",
    "\n",
    "    \"\"\"\n",
    "    if is_bgr:\n",
    "        display(Image.fromarray(img[:,:,::-1]))\n",
    "    else:\n",
    "        display(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: update this function for your preprocessing steps!\n",
    "def preprocess_image(img_path: str, img_size=img_size):\n",
    "    \"\"\"Function to prepare image for prediction\n",
    "        Args: \n",
    "            img_path: str\n",
    "            img_size: int. 224 for vgg16, 299 for xception\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray. (1, img_size, img_size, 3)\n",
    "\n",
    "    \"\"\"\n",
    "    #load image from file\n",
    "    x = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_size, img_size))\n",
    "    \n",
    "    #preprocessing steps\n",
    "    x = tf.keras.preprocessing.image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = tf.keras.applications.xception.preprocess_input(x) #tl - xception\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from file\n",
    "model = tf.keras.models.load_model(\"<model_path>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! TODO: update image path !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '<test_image_path>'\n",
    "img_size = <image_size>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show image\n",
    "original_image = cv2.imread(img_path)\n",
    "show_image(original_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict (single image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict (single image)#preprocess image\n",
    "img_ = preprocess_image(img_path)\n",
    "\n",
    "#predict\n",
    "preds = model.predict(img_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print layer names and select the conv layer!\n",
    "for layer in model.layers:\n",
    "    if layer.name == 'xception':\n",
    "        for layer2 in layer.layers:\n",
    "            print('*',layer2.name)\n",
    "    else:\n",
    "        print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: update following lines for your model\n",
    "\n",
    "#!we need to get output for xception model first! \n",
    "xception_output = model.get_layer('xception').output[:, np.argmax(preds[0])]\n",
    "\n",
    "last_conv_layer = model.get_layer('xception').get_layer(\"block14_sepconv2_act\") #TODO: update layer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check layer output\n",
    "print(last_conv_layer.output)\n",
    "last_cn_size=last_conv_layer.output.shape[-1] #2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspired by https://github.com/nickbiso/Keras-Class-Activation-Map\n",
    "grads = K.gradients(xception_output, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "iterate = K.function([ model.get_layer('xception').input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "pooled_grads_value, conv_layer_output_value = iterate([img_])\n",
    "\n",
    "for i in range(last_cn_size):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(heatmap)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#copy original image\n",
    "img = original_image.copy()\n",
    "\n",
    "#resize heatmap \n",
    "heatmap_ = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "#update pixel values : 0-1 > 0-255\n",
    "heatmap_ = np.uint8(255 * heatmap_)\n",
    "\n",
    "#combine heatmap with the original image.\n",
    "heatmap_ = cv2.applyColorMap(heatmap_, cv2.COLORMAP_JET)\n",
    "\n",
    "result_img = cv2.addWeighted(heatmap_, 0.2, img, 0.8, 0)\n",
    "result_img = np.uint8(result_img)\n",
    "\n",
    "show_image(result_img)\n",
    "print(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
